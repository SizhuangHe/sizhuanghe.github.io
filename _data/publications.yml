main:
  - title: Scaling Large Language Models for Next-Generation Single-Cell Analysis
    alt_title: "Cell2Sentence"
    authors: Syed Rizvi<sup>*</sup>, Daniel Levine<sup>*</sup>, Aakash Patel<sup>*</sup>, Shiyang Zhang<sup>*</sup>, Eric Wang<sup>*</sup>, <b><u>Sizhuang He</u></b>, David Zhang, Cerise Tang, Zhuoyang Lyu, Rayyan Darji, Marlene Li, Emily Sun, David Jeong, Lawrence Zhao, Jennifer Kwan, David Braun, Brian Hafler, Jeffrey Ishizuka, Rahul Dhodapkar, Hattie Chung, Shekoofeh Azizi, Bryan Perozzi, and David van Dijk
    date: Apr 2025
    conference_short: bioRxiv
    conference: bioRxiv
    pdf: https://www.biorxiv.org/content/10.1101/2025.04.14.648850v1.full.pdf
    # code: https://github.com/MrGiovanni/ContinualLearning
    bibtex: ./assets/bibs/c2s2.txt
    image: ./assets/img/c2s2.png
    # poster: ./assets/posters/CaLMFlow_NYAS_Poster.pdf
    blog: https://research.google/blog/teaching-machines-the-language-of-biology-scaling-large-language-models-for-next-generation-single-cell-analysis/
    notes: Preprint
    tags: ["Large Language Models", "Computational Biology", "Single-Cell Analysis"]
    selected: true
    summary: "C2S-Scale scales this framework to 27 billion parameters trained on a billion-token multimodal corpus—achieving state-of-the-art predictive and generative performance for complex, multicellular analyses."
    full_abstract: "Single-cell RNA sequencing has transformed our understanding of cellular diversity, yet current single-cell foundation models (scFMs) remain limited in their scalability, flexibility across diverse tasks, and ability to natively integrate textual information. In this work, we build upon the Cell2Sentence (C2S) framework, which represents scRNA-seq profiles as textual 'cell sentences,' to train Large Language Models (LLMs) on a corpus comprising over one billion tokens of transcriptomic data, biological text, and metadata. By scaling model size to 27 billion parameters, we observe consistent improvements in predictive and generative capabilities, as well as the capacity for advanced downstream tasks requiring synthesis of information across multicellular contexts. Through targeted fine-tuning supported by modern reinforcement learning techniques, our approach excels in tasks such as perturbation response prediction, natural language interpretation, and complex biological reasoning. By unifying transcriptomic and textual data at unprecedented scales, this approach not only surpasses both specialized single-cell models and general-purpose LLMs, but also establishes a powerful platform for next-generation single-cell analysis, paving the way for the development of 'virtual cells.'"

  - title: Non-Markovian Discrete Diffusion with Causal Language Models
    alt_title: "CaDDI"
    authors: Yangtian Zhang <sup>*</sup>, <b><u>Sizhuang He<sup>*</sup></u></b>, Daniel Levine, Lawrence Zhao, David Zhang, Syed Rizvi, Emanuele Zappala, Rex Ying, and David van Dijk
    date: Jan 2025
    conference_short: NeurIPS
    conference: NeurIPS 2025 (Poster)
    pdf: https://arxiv.org/pdf/2502.09767
    # code: https://github.com/MrGiovanni/ContinualLearning
    bibtex: ./assets/bibs/caddi.txt
    image: ./assets/img/caddi.png
    # poster: ./assets/posters/CaLMFlow_NYAS_Poster.pdf
    # notes:
    tags: ["Diffusion Models", "Causal Language Models", "Generative Modeling"]
    selected: true
    summary: "We introduce a novel approach to discrete diffusion models that conditions on the entire generative trajectory, thereby lifting the Markov constraint and allowing the model to revisit and improve past states. CaDDi treats standard causal language models as a special case and permits the direct reuse of pretrained LLM weights with no architectural changes."
    full_abstract: "Discrete diffusion models offer a flexible, controllable approach to structured sequence generation, yet they still lag behind causal language models in expressive power. A key limitation lies in their reliance on the Markovian assumption, which restricts each step to condition only on the current state, leading to potential uncorrectable error accumulation. In this paper, we introduce CaDDi, a discrete diffusion model that conditions on the entire generative trajectory, thereby lifting the Markov constraint and allowing the model to revisit and improve past states. By unifying sequential (causal) and temporal (diffusion) reasoning in a single non-Markovian transformer, CaDDi also treats standard causal language models as a special case and permits the direct reuse of pretrained LLM weights with no architectural changes. Empirically, CaDDi outperforms state-of-the-art discrete diffusion baselines on natural-language benchmarks, substantially narrowing the remaining gap to large autoregressive transformers." 

  - title: COAST&#58; Intelligent Time-Adaptive Neural Operators
    authors: Zhikai Wu, Shiyang Zhang, <b><u>Sizhuang He</u></b>, Sifan Wang, Min Zhu, Anran Jiao, Lu Lu, and David van Dijk
    date: Jan 2025
    conference_short: AI4MATH
    conference: AI4MATH Workshop at ICML 2025 (Poster)
    pdf: https://arxiv.org/pdf/2502.08574
    # code: https://github.com/MrGiovanni/ContinualLearning
    bibtex: ./assets/bibs/coast.txt
    image: ./assets/img/coast.png
    # poster: ./assets/posters/CaLMFlow_NYAS_Poster.pdf
    # notes: Accepted to AI4MATH Workshop at ICML 2025 as a poster
    tags: ["Neural Operators", "Operator Learning"]
    full_abstract: "Operator learning for time-dependent partial differential equations (PDEs) has seen rapid progress in recent years, enabling efficient approximation of complex spatiotemporal dynamics. However, most existing methods rely on fixed time step sizes during rollout, which limits their ability to adapt to varying temporal complexity and often leads to error accumulation. To address this gap, we propose the Time-Adaptive Transformer with Neural Taylor Expansion (TANTE), a novel operator-learning framework that produces continuous-time predictions with adaptive step sizes. TANTE predicts future states by performing a Taylor expansion at the current state, where neural networks learn both the higher-order temporal derivatives and the local radius of convergence. This allows the model to dynamically adjust its rollout based on the local behavior of the solution, thereby reducing cumulative error and improving computational efficiency. We demonstrate the effectiveness of TANTE across a wide range of PDE benchmarks, achieving superior accuracy and adaptability compared to fixed-step baselines, delivering accuracy gains of 10-50% and speed‑ups of 30-80% at inference."

  - title: CaLMFlow&#58; Flow Matching using Causal Language Models
    alt_title: "CaLMFlow"
    authors: <b><u>Sizhuang He<sup>*</sup></u></b>, Daniel Levine<sup>*</sup>, Ivan Vrkic, Marco Bressana, David Zhang, Syed Rizvi, Yangtian Zhang, Emanuele Zappala, and David van Dijk
    date: Oct 2024
    conference_short: ArXiv
    conference: arXiv
    pdf: https://arxiv.org/pdf/2410.05292
    # code: https://github.com/MrGiovanni/ContinualLearning
    bibtex: ./assets/bibs/calmflow.txt
    image: ./assets/img/CaLMFlow.png
    # poster: ./assets/posters/CaLMFlow_NYAS_Poster.pdf
    notes: Preprint
    tags: ["Flow Matching", "Causal Language Models", "Generative Modeling", "Integral Equations"]
    selected: true
    summary: "We present Volterra Flow Matching, a novel generative modeling framework that reformulates ODE-based flow matching frameworks with Volterra Integral Equations, hence avoiding a core challenge in ODE-based methods, known as stiffness. We show the connection between Volterra Integral Equations and causal transformers, the backbone of modern Large Language Models and hence demonstrates that causal language models can be naturally extended to generative modeling over continuous data domains through the lens of Volterra Flow Matching."
    full_abstract: "We introduce CaLMFlow, a novel framework that recasts flow matching as a Volterra integral equation (VIE) while leveraging causal language models (CLMs) for continuous data generation. Although integral equations have previously been studied for nonlocal operator learning, we are the first to apply them explicitly to flow matching. By discretizing both time and space, CaLMFlow transforms continuous trajectories into a sequence-based representation, allowing standard large language model architectures to capture long-range dependencies and flexibly incorporate textual prompts. In experiments on synthetic benchmarks and a single-cell perturbation response task, CaLMFlow demonstrates improved stability and scalability over ODE-based methods in high-dimensional regimes. These findings suggest that combining an integral-equation formulation with CLMs provides a promising, context-aware paradigm for generative modeling."

  - title: Intelligence at the Edge of Chaos
    alt_title: "Intelligence at the Edge of Chaos"
    authors: Shiyang Zhang<sup>*</sup>, Aakash Patel<sup>*</sup>, Syed Rizvi, Nianchen Liu, <b><u>Sizhuang He</u></b>, Amin Karbasi, Emanuele Zappala, and David van Dijk
    date: Oct 2024
    conference_short: ICLR
    conference: ICLR 2025 (Poster)
    pdf: https://arxiv.org/pdf/2410.02536
    # code: https://github.com/MrGiovanni/ContinualLearning
    bibtex: ./assets/bibs/complexity.txt
    image: ./assets/img/complexity.png
    # notes: Accepted to ICLR 2025 as a poster
    tags: ["Large Language Models", "Complexity Theory", "Cellular Automata"]
    selected: true
    summary: "By training LLMs on elementary cellular automata rules of varying complexity, we pinpoint a 'sweet spot' of data complexity that maximizes downstream predictive and reasoning abilities. Our findings suggest that exposing models to appropriately complex patterns is key to unlocking emergent intelligence."
    full_abstract: "We explore the emergence of intelligent behavior in artificial systems by investigating how the complexity of rule-based systems influences the capabilities of models trained to predict these rules. Our study focuses on elementary cellular automata (ECA), simple yet powerful one-dimensional systems that generate behaviors ranging from trivial to highly complex. By training distinct Large Language Models (LLMs) on different ECAs, we evaluated the relationship between the complexity of the data generated by the rules and the models' ability to learn effective general representations, as reflected in their performance on downstream tasks. Our findings reveal that models trained on more complex data exhibit greater predictive ability, as demonstrated by their performance on reasoning and chess move prediction tasks. Both uniform and periodic systems, and often also highly chaotic systems, resulted in poorer downstream performance, highlighting a sweet spot of complexity conducive to intelligence. We conjecture that intelligence arises from the ability to predict complexity and that creating intelligence may require only exposure to complexity."

  - title: Operator Learning Meets Numerical Analysis&#58; Improving Neural Networks through Iterative Methods
    authors: Emanuele Zappala, Daniel Levine, <b><u>Sizhuang He</u></b>, Syed Rizvi, Sacha L&eacute;vy, and David van Dijk
    date: Oct 2023
    conference_short: ArXiv
    conference: arXiv
    pdf: https://arxiv.org/pdf/2310.01618
    # code: https://github.com/MrGiovanni/ContinualLearning
    bibtex: ./assets/bibs/iterative_methods.txt
    image: ./assets/img/iterative_methods.png
    notes: Preprint
    tags: ["Numerical Analysis", "Operator Learning", "Integral Equations"]
    full_abstract: "Deep neural networks, despite their success in numerous applications, often function without established theoretical foundations. In this paper, we bridge this gap by drawing parallels between deep learning and classical numerical analysis. By framing neural networks as operators with fixed points representing desired solutions, we develop a theoretical framework grounded in iterative methods for operator equations. Under defined conditions, we present convergence proofs based on fixed point theory. We demonstrate that popular architectures, such as diffusion models and AlphaFold, inherently employ iterative operator learning. Empirical assessments highlight that performing iterations through network operators improves performance. We also introduce an iterative graph neural network, PIGN, that further demonstrates benefits of iterations. Our work aims to enhance the understanding of deep learning by merging insights from numerical analysis, potentially guiding the design of future networks with clearer theoretical underpinnings and improved performance."
  